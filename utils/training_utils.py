import numpy as np
from training.networks import build_siamese, Generator , build_critic
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import soundfile as sf
import IPython
import os
from utils.common import Common_helpers
from utils.inversion import Inversion_helpers
import tensorflow as tf


class Training_helpers():
    def __init__(self, args, aspec,bspec):
        self.args = args
        self.aspec = aspec
        self.bspec = bspec
        self.IH = Inversion_helpers(args)
        self.CH = Common_helpers(args)

    # Load past models from path to resume training or test
    def load(self, path):
        gen = build_generator((self.args.hop, self.args.shape, 1))
        siam = build_siamese((self.args.hop, self.args.shape, 1))
        critic = build_critic((self.args.hop, 3 * self.args.shape, 1))
        gen.load_weights(path + '/gen.h5')
        critic.load_weights(path + '/critic.h5')
        siam.load_weights(path + '/siam.h5')
        return gen, critic, siam

    # Build models

    def build(self):
        gen = Generator((self.args.hop, self.args.shape, 1))
        siam = build_siamese((self.args.hop, self.args.shape, 1))
        # the discriminator accepts as input spectrograms of triple the width of those generated by the generator
        critic = build_critic((self.args.hop, 3 * self.args.shape, 1))
        return gen, critic, siam

    # Generate a random batch to display current training results

    def testgena(self):
        sw = True
        while sw:
            a = self.aspec[0]
            if a.shape[1] // self.args.shape != 1:
                sw = False
        dsa = []
        if a.shape[1] // self.args.shape > 6:
            num = 6
        else:
            num = a.shape[1] // self.args.shape
        rn = np.random.randint(a.shape[1] - (num * self.args.shape))
        for i in range(num):
            im = a[:, rn + (i * self.args.shape):rn + (i * self.args.shape) + self.args.shape]
            im = np.reshape(im, (im.shape[0], im.shape[1], 1))
            dsa.append(im)
        return np.array(dsa, dtype=np.float32)

    def testgenb(self):
        sw = True
        while sw:
            a = self.bspec[0]
            if a.shape[1] // self.args.shape != 1:
                sw = False
        dsa = []
        if a.shape[1] // self.args.shape > 6:
            num = 6
        else:
            num = a.shape[1] // self.args.shape
        rn = np.random.randint(a.shape[1] - (num * self.args.shape))
        for i in range(num):
            im = a[:, rn + (i * self.args.shape):rn + (i * self.args.shape) + self.args.shape]
            im = np.reshape(im, (im.shape[0], im.shape[1], 1))
            dsa.append(im)
        return np.array(dsa, dtype=np.float32)

    # Show results mid-training
    def save_test_image_full(self, path, ipython=False):
        a = self.testgena()
        b = self.testgenb()
        #print(a.shape)
        ab = self.gen(a, training=False)
        ab = self.CH.testass(ab)
        a = self.CH.testass(a)
        b = self.CH.testass(b)
        abwv = self.IH.deprep(ab)
        awv = self.IH.deprep(a)
        bwv = self.IH.deprep(b)
        sf.write(path + '/generated.wav', abwv, self.args.sr)
        sf.write(path + '/source.wav', awv, self.args.sr)
        sf.write(path + '/target.wav', bwv, self.args.sr)

        if ipython:
            IPython.display.display(IPython.display.Audio(np.squeeze(abwv), rate=self.args.sr))
            IPython.display.display(IPython.display.Audio(np.squeeze(awv), rate=self.args.sr))
            IPython.display.display(IPython.display.Audio(np.squeeze(bwv), rate=self.args.sr))

        fig, axs = plt.subplots(ncols=3,figsize=(12,8))
        axs[0].imshow(np.flip(a, -2), cmap=None)
        axs[0].axis('off')
        axs[0].set_title('Source')
        axs[1].imshow(np.flip(ab, -2), cmap=None)
        axs[1].axis('off')
        axs[1].set_title('Generated')
        axs[2].imshow(np.flip(b, -2), cmap=None)
        axs[2].axis('off')
        axs[2].set_title('Target')

        plt.savefig(os.path.join(path, "spectrograms.png"), format='png')


    # Save in training loop
    # use custom save_path (i.e. Drive '../content/drive/My Drive/')
    def save_end(self, epoch, gloss, closs, mloss, n_save=3, save_path='Results'):
        if epoch % n_save == 0:
            print('Saving...')
            path = f'{save_path}/FLSGAN-VC-AB2-M-M-{str(epoch)}'
            os.mkdir(path)
            self.gen.save_weights(path + '/gen.h5')
            self.critic.save_weights(path + '/critic.h5')
            self.siam.save_weights(path + '/siam.h5')
            self.save_test_image_full(path)

    # Get models and optimizers
    def get_networks(self, load_model=False, path=None):
        if not load_model:
            gen, critic, siam = self.build()
            print('Built networks')
        else:
            gen, critic, siam = self.load(path)
            print('Loaded networks')


        opt_gen = Adam(0.0001, 0.5,0.999)  # we have used Adam as optimiser for both Generator and Discriminator
        opt_disc = Adam(0.00001, 0.5,0.999)

        self.gen = gen
        self.critic = critic
        self.siam = siam
        self.opt_gen = opt_gen
        self.opt_disc = opt_disc

        return gen, critic, siam, [opt_gen, opt_disc]

    # Set learning rate
    def update_lr(self, lr):
        print(lr)
        self.opt_gen.learning_rate = lr
        self.opt_disc.learning_rate = lr
